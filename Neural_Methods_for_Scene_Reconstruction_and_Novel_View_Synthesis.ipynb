{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8180637,"sourceType":"datasetVersion","datasetId":4843234},{"sourceId":14515920,"sourceType":"datasetVersion","datasetId":9271215}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Setup and Installation\n!nvidia-smi\n!git clone --recursive https://github.com/graphdeco-inria/gaussian-splatting.git\n%cd gaussian-splatting\n\n!pip install -q plyfile tqdm pillow opencv-python\n!pip install -q submodules/diff-gaussian-rasterization\n!pip install -q submodules/simple-knn\n\n!apt-get install -y colmap imagemagick ffmpeg\n\nimport torch\nimport os\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nprint(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T09:32:35.418762Z","iopub.execute_input":"2026-01-16T09:32:35.419410Z"}},"outputs":[{"name":"stdout","text":"Fri Jan 16 09:32:35 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nCloning into 'gaussian-splatting'...\nremote: Enumerating objects: 1053, done.\u001b[K\nremote: Total 1053 (delta 0), reused 0 (delta 0), pack-reused 1053 (from 1)\u001b[K\nReceiving objects: 100% (1053/1053), 78.70 MiB | 20.37 MiB/s, done.\nResolving deltas: 100% (607/607), done.\nSubmodule 'SIBR_viewers' (https://gitlab.inria.fr/sibr/sibr_core.git) registered for path 'SIBR_viewers'\nSubmodule 'submodules/diff-gaussian-rasterization' (https://github.com/graphdeco-inria/diff-gaussian-rasterization.git) registered for path 'submodules/diff-gaussian-rasterization'\nSubmodule 'submodules/fused-ssim' (https://github.com/rahul-goel/fused-ssim.git) registered for path 'submodules/fused-ssim'\nSubmodule 'submodules/simple-knn' (https://gitlab.inria.fr/bkerbl/simple-knn.git) registered for path 'submodules/simple-knn'\nCloning into '/kaggle/working/gaussian-splatting/SIBR_viewers'...\nremote: Enumerating objects: 3293, done.        \nremote: Counting objects: 100% (322/322), done.        \nremote: Compressing objects: 100% (174/174), done.        \nremote: Total 3293 (delta 171), reused 280 (delta 148), pack-reused 2971 (from 1)        \nReceiving objects: 100% (3293/3293), 9.98 MiB | 7.17 MiB/s, done.\nResolving deltas: 100% (2039/2039), done.\nCloning into '/kaggle/working/gaussian-splatting/submodules/diff-gaussian-rasterization'...\nremote: Enumerating objects: 329, done.        \nremote: Counting objects: 100% (205/205), done.        \nremote: Compressing objects: 100% (24/24), done.        \nremote: Total 329 (delta 183), reused 181 (delta 181), pack-reused 124 (from 1)        \nReceiving objects: 100% (329/329), 110.82 KiB | 6.52 MiB/s, done.\nResolving deltas: 100% (219/219), done.\nCloning into '/kaggle/working/gaussian-splatting/submodules/fused-ssim'...\nremote: Enumerating objects: 243, done.        \nremote: Counting objects: 100% (99/99), done.        \nremote: Compressing objects: 100% (48/48), done.        \nremote: Total 243 (delta 69), reused 55 (delta 51), pack-reused 144 (from 2)        \nReceiving objects: 100% (243/243), 5.81 MiB | 41.04 MiB/s, done.\nResolving deltas: 100% (124/124), done.\nCloning into '/kaggle/working/gaussian-splatting/submodules/simple-knn'...\nremote: Enumerating objects: 37, done.        \nremote: Counting objects: 100% (37/37), done.        \nremote: Compressing objects: 100% (34/34), done.        \nremote: Total 37 (delta 18), reused 0 (delta 0), pack-reused 0 (from 0)        \nReceiving objects: 100% (37/37), 9.46 KiB | 9.46 MiB/s, done.\nResolving deltas: 100% (18/18), done.\nSubmodule path 'SIBR_viewers': checked out 'd8856f60c5384cc1975439193bb627d77d917d77'\nSubmodule path 'submodules/diff-gaussian-rasterization': checked out '9c5c2028f6fbee2be239bc4c9421ff894fe4fbe0'\nSubmodule 'third_party/glm' (https://github.com/g-truc/glm.git) registered for path 'submodules/diff-gaussian-rasterization/third_party/glm'\nCloning into '/kaggle/working/gaussian-splatting/submodules/diff-gaussian-rasterization/third_party/glm'...\nremote: Enumerating objects: 60961, done.        \nremote: Counting objects: 100% (596/596), done.        \nremote: Compressing objects: 100% (264/264), done.        \nremote: Total 60961 (delta 456), reused 335 (delta 330), pack-reused 60365 (from 3)        \nReceiving objects: 100% (60961/60961), 72.99 MiB | 34.35 MiB/s, done.\nResolving deltas: 100% (46299/46299), done.\nSubmodule path 'submodules/diff-gaussian-rasterization/third_party/glm': checked out '5c46b9c07008ae65cb81ab79cd677ecc1934b903'\nSubmodule path 'submodules/fused-ssim': checked out '1272e21a282342e89537159e4bad508b19b34157'\nSubmodule path 'submodules/simple-knn': checked out '86710c2d4b46680c02301765dd79e465819c8f19'\n/kaggle/working/gaussian-splatting\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"pwd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input/nerf-synthetic-dataset/nerf_synthetic\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp -r /kaggle/input/nerf-synthetic-dataset/nerf_synthetic/lego /kaggle/working/lego","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 3: Convert Dataset\nSCENE_NAME = 'lego'\nSOURCE_PATH = f'/kaggle/working/{SCENE_NAME}'\n\n!python convert.py -s {SOURCE_PATH}\n\nprint(f\"Data converted for scene: {SCENE_NAME}\")\n!ls {SOURCE_PATH}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 5: Train Model (Quick - 7000 iterations)\nimport time\n\nMODEL_PATH = f'output/models/{SCENE_NAME}'\nITERATIONS = 7000\n\nos.makedirs(MODEL_PATH, exist_ok=True)\n\ntrain_cmd = f\"\"\"\npython train.py \\\n    -s {SOURCE_PATH} \\\n    -m {MODEL_PATH} \\\n    --iterations {ITERATIONS} \\\n    --test_iterations 1000 3000 7000 \\\n    --save_iterations 1000 3000 7000 \\\n    --checkpoint_iterations 1000 3000 7000 \\\n    --resolution 1 \\\n    --eval\n\"\"\"\n\nprint(\"Starting training...\")\nstart_time = time.time()\n!{train_cmd}\nend_time = time.time()\n\nprint(f\"\\nTraining completed in {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 6: Render Test Views\nRENDER_PATH = f'output/renders/{SCENE_NAME}'\n\nrender_cmd = f\"\"\"\npython render.py \\\n    -m {MODEL_PATH} \\\n    --skip_train \\\n    --iteration 7000\n\"\"\"\n\nprint(\"Rendering test views...\")\n!{render_cmd}\n\nprint(f\"Renders saved to: {MODEL_PATH}/test/ours_7000/renders\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 7: Evaluate Model\neval_cmd = f\"\"\"\npython metrics.py \\\n    -m {MODEL_PATH}\n\"\"\"\n\nprint(\"Evaluating model...\")\n!{eval_cmd}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 8: Visualize Results\nimport json\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nrenders_path = f\"{MODEL_PATH}/test/ours_7000/renders\"\ngt_path = f\"{MODEL_PATH}/test/ours_7000/gt\"\n\nrender_files = sorted(os.listdir(renders_path))[:8]\n\nfig, axes = plt.subplots(4, 4, figsize=(16, 16))\n\nfor idx, img_file in enumerate(render_files):\n    render_img = Image.open(os.path.join(renders_path, img_file))\n    gt_img = Image.open(os.path.join(gt_path, img_file))\n    \n    axes[idx*2//4, (idx*2)%4].imshow(render_img)\n    axes[idx*2//4, (idx*2)%4].set_title(f'Rendered {idx}')\n    axes[idx*2//4, (idx*2)%4].axis('off')\n    \n    axes[idx*2//4, (idx*2)%4 + 1].imshow(gt_img)\n    axes[idx*2//4, (idx*2)%4 + 1].set_title(f'Ground Truth {idx}')\n    axes[idx*2//4, (idx*2)%4 + 1].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # CELL 9: Create Video from Renders\n# video_path = f\"output/videos/{SCENE_NAME}_test.mp4\"\n# os.makedirs(os.path.dirname(video_path), exist_ok=True)\n\n# ffmpeg_cmd = f\"\"\"\n# ffmpeg -y -framerate 30 -pattern_type glob -i '{renders_path}/*.png' \\\n#     -c:v libx264 -pix_fmt yuv420p {video_path}\n# \"\"\"\n\n# !{ffmpeg_cmd}\n\n# print(f\"Video saved to: {video_path}\")\n\n# from IPython.display import Video\n# Video(video_path, width=800)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 10: Load Metrics\nresults_file = f\"{MODEL_PATH}/results.json\"\n\nif os.path.exists(results_file):\n    with open(results_file, 'r') as f:\n        results = json.load(f)\n    \n    print(\"Evaluation Metrics:\")\n    print(\"=\" * 50)\n    for key, value in results.items():\n        if isinstance(value, dict):\n            print(f\"\\n{key}:\")\n            for k, v in value.items():\n                print(f\"  {k}: {v}\")\n        else:\n            print(f\"{key}: {value}\")\n    print(\"=\" * 50)\nelse:\n    print(\"Results file not found. Run evaluation first.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 11: Render Custom Camera Path (360 rotation)\ncustom_render_path = f\"output/renders/{SCENE_NAME}_360\"\nos.makedirs(custom_render_path, exist_ok=True)\n\nrender_360_cmd = f\"\"\"\npython render.py \\\n    -m {MODEL_PATH} \\\n    --iteration 7000 \\\n    --skip_train \\\n    --skip_test\n\"\"\"\n\n!{render_360_cmd}\n\nprint(\"Custom camera path rendered\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 12: Train Full Quality (Optional - 30000 iterations)\nFULL_MODEL_PATH = f'output/models/{SCENE_NAME}_full'\nFULL_ITERATIONS = 30000\n\nos.makedirs(FULL_MODEL_PATH, exist_ok=True)\n\nfull_train_cmd = f\"\"\"\npython train.py \\\n    -s {SOURCE_PATH} \\\n    -m {FULL_MODEL_PATH} \\\n    --iterations {FULL_ITERATIONS} \\\n    --test_iterations 7000 15000 30000 \\\n    --save_iterations 7000 15000 30000 \\\n    --checkpoint_iterations 7000 15000 30000 \\\n    --resolution 1 \\\n    --eval\n\"\"\"\n\nprint(\"Starting full training (30000 iterations)...\")\nprint(\"This will take 20-30 minutes\")\n\nstart_time = time.time()\n!{full_train_cmd}\nend_time = time.time()\n\nprint(f\"\\nFull training completed in {(end_time - start_time) / 60:.2f} minutes\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 13: Process Custom Images (Optional)\nCUSTOM_PATH = \"custom-scene/custom_scene\"\n\nos.makedirs(f\"{CUSTOM_PATH}/input\", exist_ok=True)\n\nprint(\"Upload your images to /kaggle/input/ through Kaggle UI\")\nprint(\"Then run:\")\nprint(f\"!cp /kaggle/input/your-dataset/*.jpg {CUSTOM_PATH}/input/\")\nprint(f\"!python convert.py -s {CUSTOM_PATH} --colmap_executable colmap\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/input/custom-scene/custom_scene/*.jpg {CUSTOM_PATH}/input/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # CELL 14: Process Video to Images (Optional)\n# VIDEO_PATH = \"data/custom_video/video.mp4\"\n# VIDEO_OUTPUT = \"data/custom_video/images\"\n\n# os.makedirs(VIDEO_OUTPUT, exist_ok=True)\n\n# video_to_frames_cmd = f\"\"\"\n# ffmpeg -i {VIDEO_PATH} -qscale:v 1 -qmin 1 -vf fps=2 {VIDEO_OUTPUT}/%04d.jpg\n# \"\"\"\n\n# print(\"Upload your video first, then run:\")\n# print(video_to_frames_cmd)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 15: Export Point Cloud\nply_path = f\"{MODEL_PATH}/point_cloud/iteration_7000/point_cloud.ply\"\n\nif os.path.exists(ply_path):\n    print(f\"Point cloud saved at: {ply_path}\")\n    \n    from plyfile import PlyData\n    plydata = PlyData.read(ply_path)\n    \n    print(f\"Number of points: {plydata['vertex'].count}\")\n    print(f\"Properties: {plydata['vertex'].properties}\")\nelse:\n    print(\"Point cloud not found\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 16: Cleanup and Save Results\nimport shutil\n\nprint(\"Saving important files...\")\n\nfiles_to_keep = [\n    f\"{MODEL_PATH}/point_cloud/iteration_7000/point_cloud.ply\",\n    f\"{MODEL_PATH}/cameras.json\",\n    f\"{MODEL_PATH}/results.json\",\n]\n\nfor file_path in files_to_keep:\n    if os.path.exists(file_path):\n        print(f\"✓ {file_path}\")\n    else:\n        print(f\"✗ {file_path} not found\")\n\nprint(\"\\nModel training complete!\")\nprint(f\"Model saved at: {MODEL_PATH}\")\nprint(f\"Renders saved at: {MODEL_PATH}/test/ours_7000/renders\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 17: Compare Multiple Scenes\nSCENES = ['lego', 'chair', 'drums']\n\nfor scene in SCENES:\n    source = f'data/nerf_synthetic/{scene}'\n    model = f'output/models/{scene}_quick'\n    \n    print(f\"\\nProcessing {scene}...\")\n    !python convert.py -s {source}\n    !python train.py -s {source} -m {model} --iterations 5000 --resolution 2 --eval\n    !python render.py -m {model} --skip_train --iteration 5000\n    !python metrics.py -m {model}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 18: Advanced Training Options\nADVANCED_MODEL_PATH = f'output/models/{SCENE_NAME}_advanced'\n\nadvanced_train_cmd = f\"\"\"\npython train.py \\\n    -s {SOURCE_PATH} \\\n    -m {ADVANCED_MODEL_PATH} \\\n    --iterations 30000 \\\n    --position_lr_init 0.00016 \\\n    --position_lr_final 0.0000016 \\\n    --feature_lr 0.0025 \\\n    --opacity_lr 0.05 \\\n    --scaling_lr 0.005 \\\n    --rotation_lr 0.001 \\\n    --densify_grad_threshold 0.0002 \\\n    --densification_interval 100 \\\n    --opacity_reset_interval 3000 \\\n    --densify_from_iter 500 \\\n    --densify_until_iter 15000 \\\n    --sh_degree 3 \\\n    --eval\n\"\"\"\n\nprint(\"Training with custom hyperparameters...\")\n!{advanced_train_cmd}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 19: Batch Render All Test Views\nall_renders_path = f\"output/all_renders/{SCENE_NAME}\"\nos.makedirs(all_renders_path, exist_ok=True)\n\niterations = [1000, 3000, 7000]\n\nfor iter_num in iterations:\n    print(f\"\\nRendering iteration {iter_num}...\")\n    render_cmd = f\"\"\"\n    python render.py \\\n        -m {MODEL_PATH} \\\n        --iteration {iter_num} \\\n        --skip_train\n    \"\"\"\n    !{render_cmd}\n    \n    src = f\"{MODEL_PATH}/test/ours_{iter_num}/renders\"\n    dst = f\"{all_renders_path}/iter_{iter_num}\"\n    \n    if os.path.exists(src):\n        shutil.copytree(src, dst, dirs_exist_ok=True)\n        print(f\"Saved to {dst}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 20: Final Summary\nprint(\"=\" * 80)\nprint(\"TRAINING SUMMARY\")\nprint(\"=\" * 80)\nprint(f\"Scene: {SCENE_NAME}\")\nprint(f\"Model Path: {MODEL_PATH}\")\nprint(f\"Iterations: {ITERATIONS}\")\nprint()\n\nif os.path.exists(f\"{MODEL_PATH}/results.json\"):\n    with open(f\"{MODEL_PATH}/results.json\", 'r') as f:\n        results = json.load(f)\n    print(\"Metrics:\")\n    for key, value in results.items():\n        if not isinstance(value, dict):\n            print(f\"  {key}: {value}\")\n\nprint()\nprint(\"Output Files:\")\nprint(f\"  - Model: {MODEL_PATH}\")\nprint(f\"  - Renders: {MODEL_PATH}/test/ours_7000/renders\")\nprint(f\"  - Point Cloud: {MODEL_PATH}/point_cloud/iteration_7000/point_cloud.ply\")\nprint(\"=\" * 80)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}